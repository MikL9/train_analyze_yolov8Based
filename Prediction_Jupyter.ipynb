{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "name": "#%%\n"
    },
    "ExecuteTime": {
     "end_time": "2023-05-18T13:20:57.038809300Z",
     "start_time": "2023-05-18T13:20:53.672372400Z"
    }
   },
   "outputs": [],
   "source": [
    "from ultralytics import YOLO\n",
    "import cv2\n",
    "import os\n",
    "import numpy as np\n",
    "import torch\n",
    "from GPUtil import showUtilization as gpu_usage\n",
    "from numba import cuda\n",
    "\n",
    "model = YOLO(\"arkhyzS1000.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "def free_vram_func():\n",
    "    # Create a PyTorch device\n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "    # Get the free VRAM memory\n",
    "    free_vram = torch.cuda.get_device_properties(device).total_memory - torch.cuda.memory_allocated(device)\n",
    "\n",
    "    print(\"Free VRAM memory:\", free_vram, \"Allocated:\", torch.cuda.memory_allocated(device))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    },
    "ExecuteTime": {
     "end_time": "2023-05-18T13:20:57.054430700Z",
     "start_time": "2023-05-18T13:20:57.038809300Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "def free_gpu_cache():\n",
    "    print(\"Initial GPU Usage\")\n",
    "    gpu_usage()\n",
    "\n",
    "    torch.cuda.empty_cache()\n",
    "\n",
    "    cuda.select_device(0)\n",
    "    cuda.close()\n",
    "    cuda.select_device(0)\n",
    "\n",
    "    print(\"GPU Usage after emptying the cache\")\n",
    "    gpu_usage()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-05-18T13:20:57.070051300Z",
     "start_time": "2023-05-18T13:20:57.054430700Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of files in the folder: 50\n"
     ]
    }
   ],
   "source": [
    "image_folder = \"../inference_data/ideal50\"  # change this to your folder path\n",
    "images = []\n",
    "error_log = open(\"logs/files_error_log.txt\", \"a\")  # open text file for writing\n",
    "j=0\n",
    "num_files = len([f for f in os.listdir(image_folder) if os.path.isfile(os.path.join(image_folder, f))])\n",
    "\n",
    "print(\"Number of files in the folder:\", num_files)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    },
    "ExecuteTime": {
     "end_time": "2023-05-18T13:20:57.103528400Z",
     "start_time": "2023-05-18T13:20:57.070051300Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "def prepare_files():\n",
    "    global images\n",
    "    global j\n",
    "    error_status = False\n",
    "    images = []\n",
    "    j_max = j+25\n",
    "    # get a sorted list of files in the image folder\n",
    "    file_list = sorted(os.listdir(image_folder), key=lambda x: int(x.split(\"image\")[1].split(\".jpg\")[0]))\n",
    "    for file in file_list:\n",
    "        if file.endswith(\".jpg\"):\n",
    "            try:\n",
    "                # extract the image number from the file\n",
    "                image_num = int(file.split(\"image\")[1].split(\".jpg\")[0])\n",
    "                if j <= image_num <= j_max:\n",
    "                    img_path = os.path.join(image_folder, file)\n",
    "                    # read image with OpenCV\n",
    "                    img = cv2.imread(img_path)\n",
    "                    if img is None:\n",
    "                        raise IOError  # raise an error if the image is not read successfully\n",
    "                    # convert OpenCV image to numpy array\n",
    "                    img_array = np.array(img)\n",
    "                    # append to images list\n",
    "                    print(f\"append {image_num}\")\n",
    "                    images.append(img_array)\n",
    "            except (IndexError, ValueError, IOError):\n",
    "                error_status = True\n",
    "                print(f\"Unable to read image {file}\")\n",
    "                error_log.write(f\"Unable to read image {file}\\n\")\n",
    "\n",
    "    error_log.close()  # close text file when done\n",
    "    j = j_max\n",
    "    if not error_status:\n",
    "        print(\"Preparation completed with no errors!\")\n",
    "    else:\n",
    "        print(\"errors was saved to files_error_log.txt\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    },
    "ExecuteTime": {
     "end_time": "2023-05-18T13:20:57.151175300Z",
     "start_time": "2023-05-18T13:20:57.106520200Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [],
   "source": [
    "def predict_image():\n",
    "    results = model.predict(source=images, stream=True, save=True, save_txt=True, save_conf=True, conf=0.5)\n",
    "    error_log_predict = open(\"logs/prediction_error_log.txt\", \"a\")\n",
    "    for result in results:\n",
    "        boxes = result.boxes.data\n",
    "        if boxes.shape[0] == 0:\n",
    "            error_log_predict.write(f\"no detections :{j}:\\n\")\n",
    "    error_log_predict.close()\n",
    "    torch.cuda.empty_cache()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    },
    "ExecuteTime": {
     "end_time": "2023-05-18T13:20:57.151175300Z",
     "start_time": "2023-05-18T13:20:57.120484Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "append 0\n",
      "append 1\n",
      "append 2\n",
      "append 3\n",
      "append 4\n",
      "append 5\n",
      "append 6\n",
      "append 7\n",
      "append 8\n",
      "append 9\n",
      "append 10\n",
      "append 11\n",
      "append 12\n",
      "append 13\n",
      "append 14\n",
      "append 15\n",
      "append 16\n",
      "append 17\n",
      "append 18\n",
      "append 19\n",
      "append 20\n",
      "append 21\n",
      "append 22\n",
      "append 23\n",
      "append 24\n",
      "append 25\n",
      "Preparation completed with no errors!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 1280x1280 2  1.5 s, 2  1.5 s, 6  1 s, 1: 1280x1280 2  1.5 s, 2  1.5 s, 2  5 s, 2: 1280x1280 1  1.5 , 4  5 s, 1  1 , 3: 1280x1280 1  0.5 , 2  1.5 s, 2  1.5 s, 2  1 s, 4: 1280x1280 3  0.5 s, 5: 1280x1280 5  1.5 s, 6: 1280x1280 5  5 s, 7: 1280x1280 3  0.5 s, 3  1.5 s, 8: 1280x1280 3  1 s, 9: 1280x1280 3  1.5 s, 10: 1280x1280 5  0.5 s, 8  1 s, 11: 1280x1280 4  0.5 s, 3  1.5 s, 12: 1280x1280 5  0.5 s, 13: 1280x1280 3  0.5 s, 2  1.5 s, 2  1.5 s, 2  5 s, 2  0,75   s, 14: 1280x1280 4  0.5 s, 15: 1280x1280 5  1.5 s, 16: 1280x1280 6  0.5 s, 17: 1280x1280 2  1.5 s, 3  1.5 s, 18: 1280x1280 (no detections), 19: 1280x1280 2  0.5 s, 3  5 s, 20: 1280x1280 3  0.5 s, 2  1.5 s, 21: 1280x1280 6  0.5 s, 6  1 s, 22: 1280x1280 8  0.5 s, 23: 1280x1280 5  0.5 s, 24: 1280x1280 3  1.5 s, 25: 1280x1280 6  0.5 s, 951.6ms\n",
      "Speed: 10.2ms preprocess, 36.6ms inference, 1.8ms postprocess per image at shape (1, 3, 1280, 1280)\n",
      "Results saved to \u001B[1mC:\\Users\\1070PC\\PycharmProjects\\ultralytics\\runs\\detect\\predict20\u001B[0m\n",
      "25 labels saved to C:\\Users\\1070PC\\PycharmProjects\\ultralytics\\runs\\detect\\predict20\\labels\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial GPU Usage\n",
      "| ID | GPU | MEM |\n",
      "------------------\n",
      "|  0 |  1% | 18% |\n",
      "GPU Usage after emptying the cache\n",
      "| ID | GPU | MEM |\n",
      "------------------\n",
      "|  0 |  4% | 10% |\n",
      "append 25\n",
      "append 26\n",
      "append 27\n",
      "append 28\n",
      "append 29\n",
      "append 30\n",
      "append 31\n",
      "append 32\n",
      "append 33\n",
      "append 34\n",
      "append 35\n",
      "append 36\n",
      "append 37\n",
      "append 38\n",
      "append 39\n",
      "append 40\n",
      "append 41\n",
      "append 42\n",
      "append 43\n",
      "append 44\n",
      "append 45\n",
      "append 46\n",
      "append 47\n",
      "append 48\n",
      "append 49\n",
      "Preparation completed with no errors!\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "CUDA error: invalid argument\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mRuntimeError\u001B[0m                              Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[7], line 4\u001B[0m\n\u001B[0;32m      2\u001B[0m     prepare_files()\n\u001B[0;32m      3\u001B[0m     model \u001B[38;5;241m=\u001B[39m YOLO(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124markhyzS1000.pt\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n\u001B[1;32m----> 4\u001B[0m     \u001B[43mpredict_image\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m      5\u001B[0m     free_gpu_cache()\n\u001B[0;32m      6\u001B[0m \u001B[38;5;66;03m# free_vram_func()\u001B[39;00m\n",
      "Cell \u001B[1;32mIn[6], line 2\u001B[0m, in \u001B[0;36mpredict_image\u001B[1;34m()\u001B[0m\n\u001B[0;32m      1\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mpredict_image\u001B[39m():\n\u001B[1;32m----> 2\u001B[0m     results \u001B[38;5;241m=\u001B[39m \u001B[43mmodel\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mpredict\u001B[49m\u001B[43m(\u001B[49m\u001B[43msource\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mimages\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mstream\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mTrue\u001B[39;49;00m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43msave\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mTrue\u001B[39;49;00m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43msave_txt\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mTrue\u001B[39;49;00m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43msave_conf\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mTrue\u001B[39;49;00m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mconf\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;241;43m0.5\u001B[39;49m\u001B[43m)\u001B[49m\n\u001B[0;32m      3\u001B[0m     error_log_predict \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mopen\u001B[39m(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mlogs/prediction_error_log.txt\u001B[39m\u001B[38;5;124m\"\u001B[39m, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124ma\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n\u001B[0;32m      4\u001B[0m     \u001B[38;5;28;01mfor\u001B[39;00m result \u001B[38;5;129;01min\u001B[39;00m results:\n",
      "File \u001B[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\utils\\_contextlib.py:115\u001B[0m, in \u001B[0;36mcontext_decorator.<locals>.decorate_context\u001B[1;34m(*args, **kwargs)\u001B[0m\n\u001B[0;32m    112\u001B[0m \u001B[38;5;129m@functools\u001B[39m\u001B[38;5;241m.\u001B[39mwraps(func)\n\u001B[0;32m    113\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mdecorate_context\u001B[39m(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs):\n\u001B[0;32m    114\u001B[0m     \u001B[38;5;28;01mwith\u001B[39;00m ctx_factory():\n\u001B[1;32m--> 115\u001B[0m         \u001B[38;5;28;01mreturn\u001B[39;00m func(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n",
      "File \u001B[1;32m~\\PycharmProjects\\ultralytics\\ultralytics\\yolo\\engine\\model.py:250\u001B[0m, in \u001B[0;36mYOLO.predict\u001B[1;34m(self, source, stream, **kwargs)\u001B[0m\n\u001B[0;32m    248\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mtask \u001B[38;5;241m=\u001B[39m overrides\u001B[38;5;241m.\u001B[39mget(\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mtask\u001B[39m\u001B[38;5;124m'\u001B[39m) \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mtask\n\u001B[0;32m    249\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mpredictor \u001B[38;5;241m=\u001B[39m TASK_MAP[\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mtask][\u001B[38;5;241m3\u001B[39m](overrides\u001B[38;5;241m=\u001B[39moverrides, _callbacks\u001B[38;5;241m=\u001B[39m\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mcallbacks)\n\u001B[1;32m--> 250\u001B[0m     \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mpredictor\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43msetup_model\u001B[49m\u001B[43m(\u001B[49m\u001B[43mmodel\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mmodel\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mverbose\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mis_cli\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    251\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:  \u001B[38;5;66;03m# only update args if predictor is already setup\u001B[39;00m\n\u001B[0;32m    252\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mpredictor\u001B[38;5;241m.\u001B[39margs \u001B[38;5;241m=\u001B[39m get_cfg(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mpredictor\u001B[38;5;241m.\u001B[39margs, overrides)\n",
      "File \u001B[1;32m~\\PycharmProjects\\ultralytics\\ultralytics\\yolo\\engine\\predictor.py:295\u001B[0m, in \u001B[0;36mBasePredictor.setup_model\u001B[1;34m(self, model, verbose)\u001B[0m\n\u001B[0;32m    293\u001B[0m model \u001B[38;5;241m=\u001B[39m model \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39margs\u001B[38;5;241m.\u001B[39mmodel\n\u001B[0;32m    294\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39margs\u001B[38;5;241m.\u001B[39mhalf \u001B[38;5;241m&\u001B[39m\u001B[38;5;241m=\u001B[39m device\u001B[38;5;241m.\u001B[39mtype \u001B[38;5;241m!=\u001B[39m \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mcpu\u001B[39m\u001B[38;5;124m'\u001B[39m  \u001B[38;5;66;03m# half precision only supported on CUDA\u001B[39;00m\n\u001B[1;32m--> 295\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mmodel \u001B[38;5;241m=\u001B[39m \u001B[43mAutoBackend\u001B[49m\u001B[43m(\u001B[49m\u001B[43mmodel\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    296\u001B[0m \u001B[43m                         \u001B[49m\u001B[43mdevice\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mdevice\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    297\u001B[0m \u001B[43m                         \u001B[49m\u001B[43mdnn\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43margs\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mdnn\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    298\u001B[0m \u001B[43m                         \u001B[49m\u001B[43mdata\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43margs\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mdata\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    299\u001B[0m \u001B[43m                         \u001B[49m\u001B[43mfp16\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43margs\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mhalf\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    300\u001B[0m \u001B[43m                         \u001B[49m\u001B[43mfuse\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mTrue\u001B[39;49;00m\u001B[43m,\u001B[49m\n\u001B[0;32m    301\u001B[0m \u001B[43m                         \u001B[49m\u001B[43mverbose\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mverbose\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    302\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mdevice \u001B[38;5;241m=\u001B[39m device\n\u001B[0;32m    303\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mmodel\u001B[38;5;241m.\u001B[39meval()\n",
      "File \u001B[1;32m~\\PycharmProjects\\ultralytics\\ultralytics\\nn\\autobackend.py:93\u001B[0m, in \u001B[0;36mAutoBackend.__init__\u001B[1;34m(self, weights, device, dnn, data, fp16, fuse, verbose)\u001B[0m\n\u001B[0;32m     91\u001B[0m \u001B[38;5;66;03m# NOTE: special case: in-memory pytorch model\u001B[39;00m\n\u001B[0;32m     92\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m nn_module:\n\u001B[1;32m---> 93\u001B[0m     model \u001B[38;5;241m=\u001B[39m \u001B[43mweights\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mto\u001B[49m\u001B[43m(\u001B[49m\u001B[43mdevice\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m     94\u001B[0m     model \u001B[38;5;241m=\u001B[39m model\u001B[38;5;241m.\u001B[39mfuse(verbose\u001B[38;5;241m=\u001B[39mverbose) \u001B[38;5;28;01mif\u001B[39;00m fuse \u001B[38;5;28;01melse\u001B[39;00m model\n\u001B[0;32m     95\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mhasattr\u001B[39m(model, \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mkpt_shape\u001B[39m\u001B[38;5;124m'\u001B[39m):\n",
      "File \u001B[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\nn\\modules\\module.py:1145\u001B[0m, in \u001B[0;36mModule.to\u001B[1;34m(self, *args, **kwargs)\u001B[0m\n\u001B[0;32m   1141\u001B[0m         \u001B[38;5;28;01mreturn\u001B[39;00m t\u001B[38;5;241m.\u001B[39mto(device, dtype \u001B[38;5;28;01mif\u001B[39;00m t\u001B[38;5;241m.\u001B[39mis_floating_point() \u001B[38;5;129;01mor\u001B[39;00m t\u001B[38;5;241m.\u001B[39mis_complex() \u001B[38;5;28;01melse\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m,\n\u001B[0;32m   1142\u001B[0m                     non_blocking, memory_format\u001B[38;5;241m=\u001B[39mconvert_to_format)\n\u001B[0;32m   1143\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m t\u001B[38;5;241m.\u001B[39mto(device, dtype \u001B[38;5;28;01mif\u001B[39;00m t\u001B[38;5;241m.\u001B[39mis_floating_point() \u001B[38;5;129;01mor\u001B[39;00m t\u001B[38;5;241m.\u001B[39mis_complex() \u001B[38;5;28;01melse\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m, non_blocking)\n\u001B[1;32m-> 1145\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_apply\u001B[49m\u001B[43m(\u001B[49m\u001B[43mconvert\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32m~\\PycharmProjects\\ultralytics\\ultralytics\\nn\\tasks.py:150\u001B[0m, in \u001B[0;36mBaseModel._apply\u001B[1;34m(self, fn)\u001B[0m\n\u001B[0;32m    139\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21m_apply\u001B[39m(\u001B[38;5;28mself\u001B[39m, fn):\n\u001B[0;32m    140\u001B[0m \u001B[38;5;250m    \u001B[39m\u001B[38;5;124;03m\"\"\"\u001B[39;00m\n\u001B[0;32m    141\u001B[0m \u001B[38;5;124;03m    `_apply()` is a function that applies a function to all the tensors in the model that are not\u001B[39;00m\n\u001B[0;32m    142\u001B[0m \u001B[38;5;124;03m    parameters or registered buffers\u001B[39;00m\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m    148\u001B[0m \u001B[38;5;124;03m        A model that is a Detect() object.\u001B[39;00m\n\u001B[0;32m    149\u001B[0m \u001B[38;5;124;03m    \"\"\"\u001B[39;00m\n\u001B[1;32m--> 150\u001B[0m     \u001B[38;5;28mself\u001B[39m \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43msuper\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_apply\u001B[49m\u001B[43m(\u001B[49m\u001B[43mfn\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    151\u001B[0m     m \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mmodel[\u001B[38;5;241m-\u001B[39m\u001B[38;5;241m1\u001B[39m]  \u001B[38;5;66;03m# Detect()\u001B[39;00m\n\u001B[0;32m    152\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(m, (Detect, Segment)):\n",
      "File \u001B[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\nn\\modules\\module.py:797\u001B[0m, in \u001B[0;36mModule._apply\u001B[1;34m(self, fn)\u001B[0m\n\u001B[0;32m    795\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21m_apply\u001B[39m(\u001B[38;5;28mself\u001B[39m, fn):\n\u001B[0;32m    796\u001B[0m     \u001B[38;5;28;01mfor\u001B[39;00m module \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mchildren():\n\u001B[1;32m--> 797\u001B[0m         \u001B[43mmodule\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_apply\u001B[49m\u001B[43m(\u001B[49m\u001B[43mfn\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    799\u001B[0m     \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mcompute_should_use_set_data\u001B[39m(tensor, tensor_applied):\n\u001B[0;32m    800\u001B[0m         \u001B[38;5;28;01mif\u001B[39;00m torch\u001B[38;5;241m.\u001B[39m_has_compatible_shallow_copy_type(tensor, tensor_applied):\n\u001B[0;32m    801\u001B[0m             \u001B[38;5;66;03m# If the new tensor has compatible tensor type as the existing tensor,\u001B[39;00m\n\u001B[0;32m    802\u001B[0m             \u001B[38;5;66;03m# the current behavior is to change the tensor in-place using `.data =`,\u001B[39;00m\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m    807\u001B[0m             \u001B[38;5;66;03m# global flag to let the user control whether they want the future\u001B[39;00m\n\u001B[0;32m    808\u001B[0m             \u001B[38;5;66;03m# behavior of overwriting the existing tensor or not.\u001B[39;00m\n",
      "File \u001B[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\nn\\modules\\module.py:797\u001B[0m, in \u001B[0;36mModule._apply\u001B[1;34m(self, fn)\u001B[0m\n\u001B[0;32m    795\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21m_apply\u001B[39m(\u001B[38;5;28mself\u001B[39m, fn):\n\u001B[0;32m    796\u001B[0m     \u001B[38;5;28;01mfor\u001B[39;00m module \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mchildren():\n\u001B[1;32m--> 797\u001B[0m         \u001B[43mmodule\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_apply\u001B[49m\u001B[43m(\u001B[49m\u001B[43mfn\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    799\u001B[0m     \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mcompute_should_use_set_data\u001B[39m(tensor, tensor_applied):\n\u001B[0;32m    800\u001B[0m         \u001B[38;5;28;01mif\u001B[39;00m torch\u001B[38;5;241m.\u001B[39m_has_compatible_shallow_copy_type(tensor, tensor_applied):\n\u001B[0;32m    801\u001B[0m             \u001B[38;5;66;03m# If the new tensor has compatible tensor type as the existing tensor,\u001B[39;00m\n\u001B[0;32m    802\u001B[0m             \u001B[38;5;66;03m# the current behavior is to change the tensor in-place using `.data =`,\u001B[39;00m\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m    807\u001B[0m             \u001B[38;5;66;03m# global flag to let the user control whether they want the future\u001B[39;00m\n\u001B[0;32m    808\u001B[0m             \u001B[38;5;66;03m# behavior of overwriting the existing tensor or not.\u001B[39;00m\n",
      "File \u001B[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\nn\\modules\\module.py:797\u001B[0m, in \u001B[0;36mModule._apply\u001B[1;34m(self, fn)\u001B[0m\n\u001B[0;32m    795\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21m_apply\u001B[39m(\u001B[38;5;28mself\u001B[39m, fn):\n\u001B[0;32m    796\u001B[0m     \u001B[38;5;28;01mfor\u001B[39;00m module \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mchildren():\n\u001B[1;32m--> 797\u001B[0m         \u001B[43mmodule\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_apply\u001B[49m\u001B[43m(\u001B[49m\u001B[43mfn\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    799\u001B[0m     \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mcompute_should_use_set_data\u001B[39m(tensor, tensor_applied):\n\u001B[0;32m    800\u001B[0m         \u001B[38;5;28;01mif\u001B[39;00m torch\u001B[38;5;241m.\u001B[39m_has_compatible_shallow_copy_type(tensor, tensor_applied):\n\u001B[0;32m    801\u001B[0m             \u001B[38;5;66;03m# If the new tensor has compatible tensor type as the existing tensor,\u001B[39;00m\n\u001B[0;32m    802\u001B[0m             \u001B[38;5;66;03m# the current behavior is to change the tensor in-place using `.data =`,\u001B[39;00m\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m    807\u001B[0m             \u001B[38;5;66;03m# global flag to let the user control whether they want the future\u001B[39;00m\n\u001B[0;32m    808\u001B[0m             \u001B[38;5;66;03m# behavior of overwriting the existing tensor or not.\u001B[39;00m\n",
      "File \u001B[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\nn\\modules\\module.py:820\u001B[0m, in \u001B[0;36mModule._apply\u001B[1;34m(self, fn)\u001B[0m\n\u001B[0;32m    816\u001B[0m \u001B[38;5;66;03m# Tensors stored in modules are graph leaves, and we don't want to\u001B[39;00m\n\u001B[0;32m    817\u001B[0m \u001B[38;5;66;03m# track autograd history of `param_applied`, so we have to use\u001B[39;00m\n\u001B[0;32m    818\u001B[0m \u001B[38;5;66;03m# `with torch.no_grad():`\u001B[39;00m\n\u001B[0;32m    819\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m torch\u001B[38;5;241m.\u001B[39mno_grad():\n\u001B[1;32m--> 820\u001B[0m     param_applied \u001B[38;5;241m=\u001B[39m \u001B[43mfn\u001B[49m\u001B[43m(\u001B[49m\u001B[43mparam\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    821\u001B[0m should_use_set_data \u001B[38;5;241m=\u001B[39m compute_should_use_set_data(param, param_applied)\n\u001B[0;32m    822\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m should_use_set_data:\n",
      "File \u001B[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\nn\\modules\\module.py:1143\u001B[0m, in \u001B[0;36mModule.to.<locals>.convert\u001B[1;34m(t)\u001B[0m\n\u001B[0;32m   1140\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m convert_to_format \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m \u001B[38;5;129;01mand\u001B[39;00m t\u001B[38;5;241m.\u001B[39mdim() \u001B[38;5;129;01min\u001B[39;00m (\u001B[38;5;241m4\u001B[39m, \u001B[38;5;241m5\u001B[39m):\n\u001B[0;32m   1141\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m t\u001B[38;5;241m.\u001B[39mto(device, dtype \u001B[38;5;28;01mif\u001B[39;00m t\u001B[38;5;241m.\u001B[39mis_floating_point() \u001B[38;5;129;01mor\u001B[39;00m t\u001B[38;5;241m.\u001B[39mis_complex() \u001B[38;5;28;01melse\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m,\n\u001B[0;32m   1142\u001B[0m                 non_blocking, memory_format\u001B[38;5;241m=\u001B[39mconvert_to_format)\n\u001B[1;32m-> 1143\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mt\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mto\u001B[49m\u001B[43m(\u001B[49m\u001B[43mdevice\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mdtype\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43;01mif\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[43mt\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mis_floating_point\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;129;43;01mor\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[43mt\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mis_complex\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43;01melse\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[38;5;28;43;01mNone\u001B[39;49;00m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mnon_blocking\u001B[49m\u001B[43m)\u001B[49m\n",
      "\u001B[1;31mRuntimeError\u001B[0m: CUDA error: invalid argument\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n"
     ]
    }
   ],
   "source": [
    "while j < num_files:\n",
    "    prepare_files()\n",
    "    model = YOLO(\"arkhyzS1000.pt\")\n",
    "    predict_image()\n",
    "    free_gpu_cache()\n",
    "# free_vram_func()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    },
    "ExecuteTime": {
     "end_time": "2023-05-18T13:21:13.491117700Z",
     "start_time": "2023-05-18T13:20:57.151175300Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# im2 = cv2.imread(\"../inference_data/img3.jpg\")\n",
    "# if im2 is not None:\n",
    "#     print(\"Image exists.\")\n",
    "# else:\n",
    "#     print(\"Image does not exist.\")\n",
    "# results = model.predict(source=im2, save=True, save_txt=True)\n",
    "\n",
    "# results = model.predict(source=\"folder\", show=True) # Display preds. Accepts all YOLO predict arguments\n",
    "#\n",
    "# im2 = cv2.imread(\"bus.jpg\")\n",
    "# results = model.predict(source=im2, save=True, save_txt=True)  # save predictions as labels\n",
    "#\n",
    "# # from list of PIL/ndarray\n",
    "# results = model.predict(source=[im1, im2])\n",
    "#\n",
    "#\n",
    "# results = model.predict(source=0, stream=True)\n",
    "#\n",
    "# for result in results:\n",
    "#     # Detection\n",
    "#     result.boxes.xyxy   # box with xyxy format, (N, 4)\n",
    "#     result.boxes.xywh   # box with xywh format, (N, 4)\n",
    "#     result.boxes.xyxyn  # box with xyxy format but normalized, (N, 4)\n",
    "#     result.boxes.xywhn  # box with xywh format but normalized, (N, 4)\n",
    "#     result.boxes.conf   # confidence score, (N, 1)\n",
    "#     result.boxes.cls    # cls, (N, 1)\n",
    "#\n",
    "# # Each result is composed of torch.Tensor by default,\n",
    "# # in which you can easily use following functionality:\n",
    "# result = result.cuda()\n",
    "# result = result.cpu()\n",
    "# result = result.to(\"cpu\")\n",
    "# result = result.numpy()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
